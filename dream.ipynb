{
 "metadata": {
  "colabVersion": "0.3.1",
  "default_view": {},
  "name": "",
  "signature": "sha256:9b27da6778dbd040d5cc2a694260f0c1c768318984aec41630647971c21a1484",
  "views": {}
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# imports and basic notebook setup\n",
      "import matplotlib \n",
      "matplotlib.use('Agg') \n",
      "from cStringIO import StringIO\n",
      "import numpy as np\n",
      "import scipy.ndimage as nd\n",
      "import PIL.Image\n",
      "from IPython.display import clear_output, Image, display\n",
      "from google.protobuf import text_format\n",
      "\n",
      "import caffe\n",
      "\n",
      "def showarray(a, fmt='jpeg'):\n",
      "    a = np.uint8(np.clip(a, 0, 255))\n",
      "    f = StringIO()\n",
      "    PIL.Image.fromarray(a).save(f, fmt)\n",
      "    display(Image(data=f.getvalue()))\n",
      "\n",
      "model_path = '../caffe/models/bvlc_googlenet/' # substitute your path here\n",
      "net_fn   = model_path + 'deploy.prototxt'\n",
      "param_fn = model_path + 'bvlc_googlenet.caffemodel'\n",
      "\n",
      "#model_path = '../caffe/models/googlenet_places205/' # substitute your path here\n",
      "#net_fn   = model_path + 'deploy_places205.protxt'\n",
      "#param_fn = model_path + 'googlelet_places205_train_iter_2400000.caffemodel'\n",
      "\n",
      "# Patching model to be able to compute gradients.\n",
      "# Note that you can also manually add \"force_backward: true\" line to \"deploy.prototxt\".\n",
      "model = caffe.io.caffe_pb2.NetParameter()\n",
      "text_format.Merge(open(net_fn).read(), model)\n",
      "model.force_backward = True\n",
      "open('tmp.prototxt', 'w').write(str(model))\n",
      "\n",
      "net = caffe.Classifier('tmp.prototxt', param_fn,\n",
      "                       mean = np.float32([104.0, 116.0, 122.0]), # ImageNet mean, training set dependent\n",
      "                       channel_swap = (2,1,0)) # the reference model has channels in BGR order instead of RGB\n",
      "\n",
      "# a couple of utility functions for converting to and from Caffe's input image layout\n",
      "def preprocess(net, img):\n",
      "    return np.float32(np.rollaxis(img, 2)[::-1]) - net.transformer.mean['data']\n",
      "def deprocess(net, img):\n",
      "    return np.dstack((img + net.transformer.mean['data'])[::-1])\n",
      "\n",
      "def objective_L2(dst):\n",
      "    dst.diff[:] = dst.data \n",
      "\n",
      "def make_step(net, step_size=1.5, end='inception_4c/output', \n",
      "              jitter=32, clip=True, objective=objective_L2):\n",
      "    '''Basic gradient ascent step.'''\n",
      "\n",
      "    src = net.blobs['data'] # input image is stored in Net's 'data' blob\n",
      "    dst = net.blobs[end]\n",
      "\n",
      "    ox, oy = np.random.randint(-jitter, jitter+1, 2)\n",
      "    src.data[0] = np.roll(np.roll(src.data[0], ox, -1), oy, -2) # apply jitter shift\n",
      "            \n",
      "    net.forward(end=end)\n",
      "    objective(dst)  # specify the optimization objective\n",
      "    net.backward(start=end)\n",
      "    g = src.diff[0]\n",
      "    # apply normalized ascent step to the input image\n",
      "    src.data[:] += step_size/np.abs(g).mean() * g\n",
      "\n",
      "    src.data[0] = np.roll(np.roll(src.data[0], -ox, -1), -oy, -2) # unshift image\n",
      "            \n",
      "    if clip:\n",
      "        bias = net.transformer.mean['data']\n",
      "        src.data[:] = np.clip(src.data, -bias, 255-bias)   \n",
      "\n",
      "def deepdream(net, base_img, iter_n=10, octave_n=7, octave_scale=1.4, \n",
      "              end='inception_4c/output', clip=True, **step_params):\n",
      "    # prepare base images for all octaves\n",
      "    octaves = [preprocess(net, base_img)]\n",
      "    for i in xrange(octave_n-1):\n",
      "        octaves.append(nd.zoom(octaves[-1], (1, 1.0/octave_scale,1.0/octave_scale), order=1))\n",
      "    \n",
      "    src = net.blobs['data']\n",
      "    detail = np.zeros_like(octaves[-1]) # allocate image for network-produced details\n",
      "    for octave, octave_base in enumerate(octaves[::-1]):\n",
      "        h, w = octave_base.shape[-2:]\n",
      "        if octave > 0:\n",
      "            # upscale details from the previous octave\n",
      "            h1, w1 = detail.shape[-2:]\n",
      "            detail = nd.zoom(detail, (1, 1.0*h/h1,1.0*w/w1), order=1)\n",
      "\n",
      "        src.reshape(1,3,h,w) # resize the network's input image size\n",
      "        src.data[0] = octave_base+detail\n",
      "        for i in xrange(iter_n):\n",
      "            make_step(net, end=end, clip=clip, **step_params)\n",
      "            \n",
      "            # visualization\n",
      "            vis = deprocess(net, src.data[0])\n",
      "            if not clip: # adjust image contrast if clipping is disabled\n",
      "                vis = vis*(255.0/np.percentile(vis, 99.98))\n",
      "            showarray(vis)\n",
      "            print octave, i, end, vis.shape\n",
      "            clear_output(wait=True)\n",
      "            \n",
      "        # extract details produced on the current octave\n",
      "        detail = src.data[0]-octave_base\n",
      "       \n",
      "    # returning the resulting image\n",
      "    return deprocess(net, src.data[0])\n",
      "\n",
      "img = np.float32(PIL.Image.open('/home/spiorf/Scrivania/a.jpg'))\n",
      "showarray(img)\n"
     ],
     "language": "python",
     "metadata": {
      "cellView": "both",
      "colab_type": "code",
      "id": "Pqz5k4syOZNA"
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/matplotlib/__init__.py:1318: UserWarning:  This call to matplotlib.use() has no effect\n",
        "because the backend has already been chosen;\n",
        "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
        "or matplotlib.backends is imported for the first time.\n",
        "\n",
        "  warnings.warn(_use_error_msg)\n"
       ]
      },
      {
       "ename": "TypeError",
       "evalue": "constructor returned NULL",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-3-f05b79a4c92c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtext_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcaffe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mshowarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'jpeg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/root/caffe/python/caffe/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpycaffe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSGDSolver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_caffe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mset_mode_cpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_mode_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_solver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaffe_pb2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTEST\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdetector\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDetector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/root/caffe/python/caffe/pycaffe.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_caffe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSGDSolver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcaffe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# We directly update methods from Net here (rather than using composition or\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/root/caffe/python/caffe/io.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mzoom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/skimage/io/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mreset_plugins\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mWRAP_LEN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m73\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/skimage/io/manage_plugins.pyc\u001b[0m in \u001b[0;36mreset_plugins\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreset_plugins\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0m_clear_plugins\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0m_load_preferred_plugins\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/skimage/io/manage_plugins.pyc\u001b[0m in \u001b[0;36m_load_preferred_plugins\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mio_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'imsave'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'imshow'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'imread_collection'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'imread'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mio_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0m_set_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreferred_plugins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'all'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mplugin_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreferred_plugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'all'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/skimage/io/manage_plugins.pyc\u001b[0m in \u001b[0;36m_set_plugin\u001b[0;34m(plugin_type, plugin_list)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0muse_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplugin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplugin_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/skimage/io/manage_plugins.pyc\u001b[0m in \u001b[0;36muse_plugin\u001b[0;34m(name, kind)\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mkind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/skimage/io/manage_plugins.pyc\u001b[0m in \u001b[0;36m_load\u001b[0;34m(plugin)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0mmodname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplugin_module_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mplugin\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         plugin_module = __import__('skimage.io._plugins.' + modname,\n\u001b[0;32m--> 295\u001b[0;31m                                    fromlist=[modname])\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0mprovides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplugin_provides\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mplugin\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/skimage/io/_plugins/matplotlib_plugin.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexposure\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_low_contrast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpylab_setup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m \u001b[0m_backend_mod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_figure_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdraw_if_interactive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_show\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpylab_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/backends/__init__.pyc\u001b[0m in \u001b[0;36mpylab_setup\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# imports. 0 means only perform absolute imports.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     backend_mod = __import__(backend_name,\n\u001b[0;32m---> 32\u001b[0;31m                              globals(),locals(),[backend_name],0)\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# Things we pull in from all backends\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/backends/backend_gtk3agg.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend_agg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend_gtk3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackend_cairo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcairo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHAS_CAIRO_CFFI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFigure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/backends/backend_gtk3.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m cursord = {\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mcursors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMOVE\u001b[0m          \u001b[0;34m:\u001b[0m \u001b[0mGdk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGdk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCursorType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFLEUR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0mcursors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHAND\u001b[0m          \u001b[0;34m:\u001b[0m \u001b[0mGdk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGdk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCursorType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHAND2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mcursors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPOINTER\u001b[0m       \u001b[0;34m:\u001b[0m \u001b[0mGdk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGdk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCursorType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLEFT_PTR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mTypeError\u001b[0m: constructor returned NULL"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "#img=deepdream(net, img, end='inception_4e/5x5')\n",
      "    \n",
      "    \n",
      "blobs = net.blobs.keys()\n",
      "blob_len=len(blobs)\n",
      "!mkdir /home/spiorf/Scrivania/londra2\n",
      "frame = img\n",
      "frame_i = 3\n",
      "h, w = frame.shape[:2]\n",
      "s = 0.00 # scale coefficient\n",
      "while frame_i <= blob_len:\n",
      "    frame = frame * 0.5 + img * 0.5\n",
      "    frame = deepdream(net, frame,end=blobs[frame_i])\n",
      "    PIL.Image.fromarray(np.uint8(frame)).save(\"/home/spiorf/Scrivania/londra2/%04d.jpg\"%frame_i)\n",
      "    frame = nd.affine_transform(frame, [1-s,1-s,1], [h*s/2,w*s/2,0], order=1)\n",
      "    frame_i += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Controlling dreams\n",
      "\n",
      "The image detail generation method described above tends to produce some patterns more often the others. One easy way to improve the generated image diversity is to tweak the optimization objective. Here we show just one of many ways to do that. Let's use one more input image. We'd call it a \"*guide*\"."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "guide = np.float32(PIL.Image.open('/home/spiorf/Scrivania/barcode.jpg'))\n",
      "showarray(guide)\n",
      "end = 'inception_5b/output'\n",
      "h, w = guide.shape[:2]\n",
      "src, dst = net.blobs['data'], net.blobs[end]\n",
      "src.reshape(1,3,h,w)\n",
      "src.data[0] = preprocess(net, guide)\n",
      "net.forward(end=end)\n",
      "guide_features = dst.data[0].copy()\n",
      "\n",
      "def objective_guide(dst):\n",
      "    x = dst.data[0].copy()\n",
      "    y = guide_features\n",
      "    ch = x.shape[0]\n",
      "    x = x.reshape(ch,-1)\n",
      "    y = y.reshape(ch,-1)\n",
      "    A = x.T.dot(y) # compute the matrix of dot-products with guide features\n",
      "    dst.diff[0].reshape(ch,-1)[:] = y[:,A.argmax(1)] # select ones that match best"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0a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\ntyq3cA4GR74qWiiiiiiiiiiiiiiiiiiiiiiiiiiiiv/Z\n",
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Image at 0x7f9f50a33d90>"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that the neural network we use was trained on images downscaled to 224x224 size. So high resolution images might have to be downscaled, so that the network could pick up their features. The image we use here is already small enough.\n",
      "\n",
      "Now we pick some target layer and extract guide image features."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Instead of maximizing the L2-norm of current image activations, we try to maximize the dot-products between activations of current image, and their best matching correspondences from the guide image."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "_=deepdream(net, img, end=end, objective=objective_guide)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "This way we can affect the style of generated images without using a different training set."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}